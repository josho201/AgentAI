####


###Simple Deep Research

A ver, tengo que definir la meta final del proyecto, debe ser algo claro, mas o menos peciso, mas o menos alcanzable, etc, etc. debe ser una cosa. Una sola cosa y nada m√°s. por ahora el uso que tiene es deep research entonces eso ser√°.
¬øque hay implementado ya? 
- un web scaper
- busqueda en google
- Guardar archivos ???

que podria ser util implementar? 

- en el tool para extraer contenido de paginas web, a√±adir un campo de "infomacion para extraer/preferencial", indexar el texto de la pagina y luego devolver al modelo las secciones de la pagina m√°s utiles. Adem√°s, tambi√©n ayudaria a usar menos tokens (y asi prevenir context rot) al darle al modelo, en teoria, solo informaci√≥n util. quiza como campo opcional del web scrapper, o como tool indibvidual? 
- guardar los reportes diectamente como rich text y no markdown tambipen seria algo bastabte util 
- La directiva completa del prompt tambi√©n me parece algo que hay que cambiar porque me parece demamsiado rigida, google-> scrap sin interar en ese ciclo, probablemente deberia haber un par de rondas de abstracci√≥n despues de tener el resultado dado por google
# Simple Deep Research

**Simple Deep Research** es una herramienta ligera de investigaci√≥n automatizada construida con [qwen-agent](https://github.com/QwenLM/qwen-agent).  
Su objetivo es asistir en procesos de **deep research** mediante un ciclo de b√∫squeda, extracci√≥n, organizaci√≥n e integraci√≥n de informaci√≥n.

---

## ‚ú® Capacidades principales

- **B√∫squeda en Google**
  - Generaci√≥n autom√°tica de queries a partir de la necesidad de investigaci√≥n.
  - Iteraci√≥n de consultas para obtener resultados m√°s espec√≠ficos.

- **Extracci√≥n de contenido web**
  - Web scraper integrado.
  - Posibilidad de definir *informaci√≥n preferencial* (ej: "extraer estad√≠sticas", "extraer definiciones").
  - Indexaci√≥n del contenido en fragmentos relevantes para reducir consumo de tokens.
  - Selecci√≥n de secciones m√°s √∫tiles para el modelo.

- **Gesti√≥n de memoria del proyecto**
  - Almacenamiento de hallazgos en archivos persistentes.
  - Base de conocimiento incremental para evitar duplicar b√∫squedas.
  - Posibilidad de consultar qu√© informaci√≥n ya fue recolectada en runs previos.

- **Procesamiento iterativo**
  - Ciclo de reflexi√≥n + acci√≥n: el agente decide si debe realizar m√°s b√∫squedas o si ya puede producir un reporte.
  - M√°ximo configurable de rondas de iteraci√≥n.

- **Generaci√≥n de reportes enriquecidos**
  - Exportaci√≥n a **Rich Text (RTF)** o **HTML**, con soporte b√°sico para Markdown.
  - Inclusi√≥n de secciones jer√°rquicas:
    - Hechos crudos
    - Res√∫menes anal√≠ticos
    - Conclusiones / hip√≥tesis
  - Referencias con URLs a las fuentes utilizadas.

- **Control del nivel de abstracci√≥n**
  - El usuario puede especificar el nivel de profundidad del reporte:
    - Nivel 1 ‚Üí Datos crudos.
    - Nivel 2 ‚Üí S√≠ntesis y an√°lisis.
    - Nivel 3 ‚Üí Conclusiones, hip√≥tesis y conexiones.


---

## üöÄ Uso b√°sico

1. Define un **tema de investigaci√≥n**.
2. Lanza el agente con una query inicial.
3. El sistema:
   - Busca en Google.
   - Extrae y procesa p√°ginas relevantes.
   - Itera seg√∫n necesidad.
   - Genera un reporte enriquecido.
4. Consulta el resultado en la carpeta `research_outputs`.

---

## üîÆ Roadmap

- [ ] Integraci√≥n con PDFs y documentos locales.  
- [ ] Soporte para exportar a DOCX y LaTeX.  
- [ ] Panel web interactivo para gesti√≥n de investigaciones.  
